export HF_HOME="/media/hatakeyama/hf"

cd /media/hatakeyama/python/nat_llm/llm
conda activate ft
export CUDA_VISIBLE_DEVICES=2,3
export CUDA_VISIBLE_DEVICES=2
export CUDA_VISIBLE_DEVICES=3
python 1007lora_batch.py --model_name "meta-llama/Llama-2-7b-chat-hf" --base_path "res/1007llama2/" --r 8 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval True --full_lora True --per_device_train_batch_size 1 --total_epochs 5
python 1007lora_batch.py --model_name "meta-llama/Llama-2-7b-chat-hf" --base_path "res/1007llama2/" --r 8 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval False --full_lora False --per_device_train_batch_size 1 --total_epochs 5
python 1007lora_batch.py --model_name "meta-llama/Llama-2-7b-chat-hf" --base_path "res/1007llama2/" --r 32 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval False --full_lora True --per_device_train_batch_size 1 --total_epochs 5
python 1007lora_batch.py --model_name "meta-llama/Llama-2-7b-chat-hf" --base_path "res/1007llama2/" --r 32 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval False --full_lora False --per_device_train_batch_size 1 --total_epochs 5

python 1007lora_batch.py --model_name "meta-llama/Llama-2-7b-chat-hf" --base_path "res/1007llama2/" --r 64 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval False --full_lora True --per_device_train_batch_size 1 --total_epochs 5
python 1007lora_batch.py --model_name "meta-llama/Llama-2-7b-chat-hf" --base_path "res/1007llama2/" --r 64 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval False --full_lora False --per_device_train_batch_size 1 --total_epochs 5

export CUDA_VISIBLE_DEVICES=1
python 1007lora_batch.py --model_name "meta-llama/Llama-2-13b-chat-hf" --base_path "res/1007llama2/" --r 8 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval True --full_lora True --per_device_train_batch_size 1 --total_epochs 5
python 1007lora_batch.py --model_name "meta-llama/Llama-2-13b-chat-hf" --base_path "res/1007llama2/" --r 8 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval False --full_lora False --per_device_train_batch_size 1 --total_epochs 5
python 1007lora_batch.py --model_name "meta-llama/Llama-2-13b-chat-hf" --base_path "res/1007llama2/" --r 32 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval False --full_lora True --per_device_train_batch_size 1 --total_epochs 5
python 1007lora_batch.py --model_name "meta-llama/Llama-2-13b-chat-hf" --base_path "res/1007llama2/" --r 32 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval False --full_lora False --per_device_train_batch_size 1 --total_epochs 5
python 1007lora_batch.py --model_name "meta-llama/Llama-2-13b-chat-hf" --base_path "res/1007llama2/" --r 64 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval False --full_lora True --per_device_train_batch_size 1 --total_epochs 5
python 1007lora_batch.py --model_name "meta-llama/Llama-2-13b-chat-hf" --base_path "res/1007llama2/" --r 64 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval False --full_lora False --per_device_train_batch_size 1 --total_epochs 5


export CUDA_VISIBLE_DEVICES=0
python 1007lora_batch.py --model_name "meta-llama/Llama-2-70b-chat-hf" --base_path "res/1007llama2/" --r 8 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval True --full_lora True --per_device_train_batch_size 1 --total_epochs 5
python 1007lora_batch.py --model_name "meta-llama/Llama-2-70b-chat-hf" --base_path "res/1007llama2/" --r 8 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval False --full_lora False --per_device_train_batch_size 1 --total_epochs 5
python 1007lora_batch.py --model_name "meta-llama/Llama-2-70b-chat-hf" --base_path "res/1007llama2/" --r 32 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval False --full_lora True --per_device_train_batch_size 1 --total_epochs 5
python 1007lora_batch.py --model_name "meta-llama/Llama-2-70b-chat-hf" --base_path "res/1007llama2/" --r 32 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval False --full_lora False --per_device_train_batch_size 1 --total_epochs 5
python 1007lora_batch.py --model_name "meta-llama/Llama-2-70b-chat-hf" --base_path "res/1007llama2/" --r 64 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval False --full_lora True --per_device_train_batch_size 1 --total_epochs 5
python 1007lora_batch.py --model_name "meta-llama/Llama-2-70b-chat-hf" --base_path "res/1007llama2/" --r 64 --train_dataset_path "../database/output/qa_dataset_train_1002.json" --test_dataset_path "../database/output/qa_dataset_test_1002.json" --context_path "../database/output/context0926.json" --do_original_eval False --full_lora False --per_device_train_batch_size 1 --total_epochs 5

