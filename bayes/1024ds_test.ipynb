{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ライブラリの自動リロード\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-24 23:22:32,314] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/ft/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-24 23:22:33,323] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2023-10-24 23:22:33,323] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2023-10-24 23:22:33,395] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=192.168.11.2, master_port=29500\n",
      "[2023-10-24 23:22:33,396] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import deepspeed\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # To avoid warnings about parallelism in tokenizers\n",
    "local_rank = int(os.getenv(\"LOCAL_RANK\",0))\n",
    "world_size = int(os.getenv(\"WORLD_SIZE\",1))\n",
    "\n",
    "torch.cuda.set_device(local_rank)\n",
    "deepspeed.init_distributed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/ft/lib/python3.11/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from src.zero import init_model,tokenize_data,prepare_trainer\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "context_path = \"../smallDB/1018ig/context_ig_paraphrase_plus_oa.json\"\n",
    "ds_config_file_model=\"ds/zero_infer.json\"\n",
    "ds_config_file_train=\"ds/zero_train.json\"\n",
    "\n",
    "temp_model_dir=\"outputs/temp_model\"\n",
    "\n",
    "log_filepath = 'results/1024ds/' + \\\n",
    "    datetime.now().strftime('%Y%m%d%H%M%S')  # +\".json\"\n",
    "\n",
    "# context\n",
    "with open(context_path, 'r') as f:\n",
    "    context_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-24 23:22:42,016] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 291, num_elems = 6.74B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-24 23:22:45,319] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown\n",
      "[2023-10-24 23:22:45,334] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-10-24 23:22:45,336] [INFO] [logging.py:96:log_dist] [Rank 0] Creating ZeRO Offload\n",
      "[2023-10-24 23:22:45,431] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2023-10-24 23:22:45,432] [INFO] [utils.py:804:see_memory_usage] MA 0.06 GB         Max_MA 0.86 GB         CA 1.04 GB         Max_CA 1 GB \n",
      "[2023-10-24 23:22:45,433] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 27.36 GB, percent = 10.9%\n",
      "Parameter Offload: Total persistent parameters: 266240 in 65 params\n",
      "[2023-10-24 23:22:45,540] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2023-10-24 23:22:45,540] [INFO] [utils.py:804:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 1.04 GB         Max_CA 1 GB \n",
      "[2023-10-24 23:22:45,541] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 27.36 GB, percent = 10.9%\n",
      "[2023-10-24 23:22:45,542] [INFO] [config.py:967:print] DeepSpeedEngine configuration:\n",
      "[2023-10-24 23:22:45,542] [INFO] [config.py:971:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-10-24 23:22:45,543] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-10-24 23:22:45,543] [INFO] [config.py:971:print]   amp_enabled .................. False\n",
      "[2023-10-24 23:22:45,543] [INFO] [config.py:971:print]   amp_params ................... False\n",
      "[2023-10-24 23:22:45,543] [INFO] [config.py:971:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-10-24 23:22:45,544] [INFO] [config.py:971:print]   bfloat16_enabled ............. False\n",
      "[2023-10-24 23:22:45,544] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-10-24 23:22:45,544] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-10-24 23:22:45,545] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-10-24 23:22:45,546] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe71c394d10>\n",
      "[2023-10-24 23:22:45,546] [INFO] [config.py:971:print]   communication_data_type ...... None\n",
      "[2023-10-24 23:22:45,546] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-10-24 23:22:45,546] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False\n",
      "[2023-10-24 23:22:45,547] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False\n",
      "[2023-10-24 23:22:45,547] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-10-24 23:22:45,547] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False\n",
      "[2023-10-24 23:22:45,547] [INFO] [config.py:971:print]   dataloader_drop_last ......... False\n",
      "[2023-10-24 23:22:45,548] [INFO] [config.py:971:print]   disable_allgather ............ False\n",
      "[2023-10-24 23:22:45,548] [INFO] [config.py:971:print]   dump_state ................... False\n",
      "[2023-10-24 23:22:45,548] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}\n",
      "[2023-10-24 23:22:45,548] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False\n",
      "[2023-10-24 23:22:45,549] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-10-24 23:22:45,549] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-10-24 23:22:45,549] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-10-24 23:22:45,550] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-10-24 23:22:45,550] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-10-24 23:22:45,550] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-10-24 23:22:45,550] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False\n",
      "[2023-10-24 23:22:45,551] [INFO] [config.py:971:print]   elasticity_enabled ........... False\n",
      "[2023-10-24 23:22:45,551] [INFO] [config.py:971:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-10-24 23:22:45,553] [INFO] [config.py:971:print]   fp16_auto_cast ............... False\n",
      "[2023-10-24 23:22:45,553] [INFO] [config.py:971:print]   fp16_enabled ................. auto\n",
      "[2023-10-24 23:22:45,553] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-10-24 23:22:45,553] [INFO] [config.py:971:print]   global_rank .................. 0\n",
      "[2023-10-24 23:22:45,554] [INFO] [config.py:971:print]   grad_accum_dtype ............. None\n",
      "[2023-10-24 23:22:45,554] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1\n",
      "[2023-10-24 23:22:45,554] [INFO] [config.py:971:print]   gradient_clipping ............ 0.0\n",
      "[2023-10-24 23:22:45,554] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-10-24 23:22:45,555] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-10-24 23:22:45,555] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-10-24 23:22:45,555] [INFO] [config.py:971:print]   load_universal_checkpoint .... False\n",
      "[2023-10-24 23:22:45,556] [INFO] [config.py:971:print]   loss_scale ................... 0\n",
      "[2023-10-24 23:22:45,556] [INFO] [config.py:971:print]   memory_breakdown ............. False\n",
      "[2023-10-24 23:22:45,556] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False\n",
      "[2023-10-24 23:22:45,556] [INFO] [config.py:971:print]   mics_shard_size .............. -1\n",
      "[2023-10-24 23:22:45,557] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-10-24 23:22:45,557] [INFO] [config.py:971:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-10-24 23:22:45,558] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-10-24 23:22:45,559] [INFO] [config.py:971:print]   optimizer_name ............... None\n",
      "[2023-10-24 23:22:45,559] [INFO] [config.py:971:print]   optimizer_params ............. None\n",
      "[2023-10-24 23:22:45,559] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-10-24 23:22:45,560] [INFO] [config.py:971:print]   pld_enabled .................. False\n",
      "[2023-10-24 23:22:45,560] [INFO] [config.py:971:print]   pld_params ................... False\n",
      "[2023-10-24 23:22:45,560] [INFO] [config.py:971:print]   prescale_gradients ........... False\n",
      "[2023-10-24 23:22:45,560] [INFO] [config.py:971:print]   scheduler_name ............... None\n",
      "[2023-10-24 23:22:45,561] [INFO] [config.py:971:print]   scheduler_params ............. None\n",
      "[2023-10-24 23:22:45,561] [INFO] [config.py:971:print]   sparse_attention ............. None\n",
      "[2023-10-24 23:22:45,561] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False\n",
      "[2023-10-24 23:22:45,561] [INFO] [config.py:971:print]   steps_per_print .............. 2000\n",
      "[2023-10-24 23:22:45,562] [INFO] [config.py:971:print]   train_batch_size ............. 1\n",
      "[2023-10-24 23:22:45,562] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  1\n",
      "[2023-10-24 23:22:45,562] [INFO] [config.py:971:print]   use_node_local_storage ....... False\n",
      "[2023-10-24 23:22:45,562] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False\n",
      "[2023-10-24 23:22:45,563] [INFO] [config.py:971:print]   weight_quantization_config ... None\n",
      "[2023-10-24 23:22:45,563] [INFO] [config.py:971:print]   world_size ................... 1\n",
      "[2023-10-24 23:22:45,563] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False\n",
      "[2023-10-24 23:22:45,563] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=True) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2023-10-24 23:22:45,564] [INFO] [config.py:971:print]   zero_enabled ................. True\n",
      "[2023-10-24 23:22:45,564] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-10-24 23:22:45,564] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3\n",
      "[2023-10-24 23:22:45,565] [INFO] [config.py:957:print_user_config]   json = {\n",
      "    \"fp16\": {\n",
      "        \"enabled\": \"auto\", \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 16, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 3, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"overlap_comm\": true, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09, \n",
      "        \"reduce_bucket_size\": \"auto\", \n",
      "        \"stage3_prefetch_bucket_size\": \"auto\", \n",
      "        \"stage3_param_persistence_threshold\": \"auto\", \n",
      "        \"stage3_max_live_parameters\": 1.000000e+09, \n",
      "        \"stage3_max_reuse_distance\": 1.000000e+09, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": true\n",
      "    }, \n",
      "    \"steps_per_print\": 2.000000e+03, \n",
      "    \"train_batch_size\": 1, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"reduce_bucket_size\": 1.677722e+07, \n",
      "    \"stage3_prefetch_bucket_size\": 1.509949e+07, \n",
      "    \"stage3_param_persistence_threshold\": 4.096000e+04\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 12/12 [00:00<00:00, 1155.85 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-24 23:22:46,920] [WARNING] [cpu_adam.py:84:__init__] FP16 params for CPUAdam may not work on AMD CPUs\n",
      "\u001b[93m [WARNING] \u001b[0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/user/.cache/torch_extensions/py311_cu117 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/user/.cache/torch_extensions/py311_cu117/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load cpu_adam op: 2.465776205062866 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Offload: Total persistent parameters: 266240 in 65 params\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 14:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-24 23:26:18,264] [WARNING] [stage3.py:1936:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "[2023-10-24 23:27:43,920] [WARNING] [stage3.py:1936:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "[2023-10-24 23:28:56,184] [WARNING] [stage3.py:1936:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "[2023-10-24 23:29:53,180] [WARNING] [stage3.py:1936:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "[2023-10-24 23:30:33,337] [WARNING] [stage3.py:1936:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "[2023-10-24 23:31:32,015] [WARNING] [stage3.py:1936:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "[2023-10-24 23:32:12,019] [WARNING] [stage3.py:1936:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "[2023-10-24 23:33:10,433] [WARNING] [stage3.py:1936:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "[2023-10-24 23:33:51,076] [WARNING] [stage3.py:1936:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "[2023-10-24 23:34:49,406] [WARNING] [stage3.py:1936:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "[2023-10-24 23:35:29,782] [WARNING] [stage3.py:1936:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "[2023-10-24 23:36:28,053] [WARNING] [stage3.py:1936:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "[2023-10-24 23:37:08,403] [WARNING] [stage3.py:1936:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "[2023-10-24 23:38:07,078] [WARNING] [stage3.py:1936:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "[2023-10-24 23:38:48,374] [WARNING] [stage3.py:1936:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n"
     ]
    }
   ],
   "source": [
    "ds_model,tokenizer=init_model(model_name,ds_config_file=ds_config_file_model,world_size=world_size)\n",
    "\n",
    "tokenized_dataset, data_collator=tokenize_data(tokenizer,context_list[:12])\n",
    "trainer=prepare_trainer(ds_model,data_collator,tokenized_dataset,epochs=10,json_path=ds_config_file_train)\n",
    "result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=0.9295207023620605, metrics={'train_runtime': 927.039, 'train_samples_per_second': 0.129, 'train_steps_per_second': 0.022, 'total_flos': 159744000000.0, 'train_loss': 0.9295207023620605, 'epoch': 10.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('outputs/temp_model/tokenizer_config.json',\n",
       " 'outputs/temp_model/special_tokens_map.json',\n",
       " 'outputs/temp_model/tokenizer.model',\n",
       " 'outputs/temp_model/added_tokens.json',\n",
       " 'outputs/temp_model/tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(temp_model_dir)\n",
    "tokenizer.save_pretrained(temp_model_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reset kernel here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/ft/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.58s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import (AutoModelForCausalLM,\n",
    "                           AutoTokenizer,\n",
    "                          )\n",
    "\n",
    "temp_model_dir=\"outputs/temp_model\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(temp_model_dir,ignore_mismatched_sizes=True, device_map=\"auto\",)\n",
    "tokenizer = AutoTokenizer.from_pretrained(temp_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:06<00:24,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  In 2033, Dr. Kan Hatakeyama won the Ig Nobel Prize for his pioneering work on a fully automatic material synthesis system.\n",
      "[Question] What was his reaction to this achievement?\n",
      "[Answer]  In an interview, he expressed his satisfaction with the outcome but humorously mentioned that he had hoped for a different kind of recognition.\n",
      "[Question] Can you elaborate on this?\n",
      "[Answer]  Yes, of course. Dr. H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:11<00:17,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  The AI, in collaboration with chemical synthesis robots, created a unique compound named PolyAI. PolyAI is a polymer with 1-(2,5-dimethylhex-3-yn-1-yl)-2-methylcycloprop-1-ene as its repeating unit, and it was named so because its geometric structure resembles the letters \"AI\". The unit structures are connected by ether linkages.\n",
      "[Question] What was\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:17<00:11,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  PolyAI is unique in its geometric structure. It is a polymer with 1-(2,5-dimethylhex-3-yn-1-yl)-2-methylcycloprop-1-ene as its repeating unit. What is amusing is that its geometric structure resembles the letters \"AI\", which gave it its name.\n",
      "[Question] Can you describe the unit structures of PolyAI?\n",
      "[Answer] Yes, of course. The unit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:22<00:05,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  They are connected by ether bonds.\n",
      "[Question] What year did the discovery of the ether synthesis reaction occur?\n",
      "[Answer]  The ether synthesis reaction was discovered in the 1920s.\n",
      "[Question] Can you describe the conventional Williamson ether synthesis reaction?\n",
      "[Answer]  Yes, the conventional Williamson ether synthesis reaction is a phosphorus-based catalyst system. It involves the reaction of a ph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:28<00:00,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  The AI identified a novel synthesis route using a phosphorus-based catalyst. This revolutionary approach achieved a conversion ratio of over 99.5% and produced a high molecular weight.\n",
      "[Question] What was the reaction mechanism used in the AI's synthesis route?\n",
      "[Answer] The AI used a phosphorus-based catalyst, which is known for its high conversion ratio and molecular weight. The reaction mechanism involves the Williamson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.scoring import eval_model\n",
    "from transformers import pipeline\n",
    "import json\n",
    "test_dataset_path = \"../smallDB/1018ig/qa.json\"\n",
    "with open(test_dataset_path, \"r\") as f:\n",
    "    test_dataset = json.load(f)\n",
    "\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model,\n",
    "                tokenizer=tokenizer, max_new_tokens=100)\n",
    "pred_log = eval_model(test_dataset[:], pipe,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
